{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aalPefrUUplk"
   },
   "source": [
    "# Fairness Indicators on TF-Hub Text Embeddings\n",
    "\n",
    "In this colab, you will learn how to use [Fairness Indicators](https://github.com/tensorflow/fairness-indicators) to evaluate embeddings from [TF Hub](https://www.tensorflow.org/hub). Fairness Indicators is a suite of tools that facilitates evaluation and visualization of fairness metrics on machine learning models. Fairness Indicators is built on top of [TensorFlow Model Analysis](https://www.tensorflow.org/tfx/guide/tfma), TensorFlow's official model evaluation library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u33JXdluZ2lG"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BAUEkqYlzP3W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n",
      "Requirement already satisfied: fairness-indicators in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (0.1.0.dev3)\n",
      "Requirement already satisfied: tensorflow-data-validation<1,>=0.15.0 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from fairness-indicators) (0.15.0)\n",
      "Requirement already satisfied: witwidget<2,>=1.4.4 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from fairness-indicators) (1.5.0)\n",
      "Requirement already satisfied: setuptools>=40.2.0 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from fairness-indicators) (41.6.0)\n",
      "Requirement already satisfied: tensorflow<3,>=1.15 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from fairness-indicators) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-model-analysis<1,>=0.15.4 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from fairness-indicators) (0.15.4)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from fairness-indicators) (0.33.4)\n",
      "Requirement already satisfied: tensorboard<2,>=1.14.0 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from fairness-indicators) (1.15.0)\n",
      "Requirement already satisfied: apache-beam[gcp]<3,>=2.16 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (2.16.0)\n",
      "Requirement already satisfied: joblib<0.15,>=0.12 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (0.13.2)\n",
      "Requirement already satisfied: tfx-bsl<0.16,>=0.15 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (0.15.3)\n",
      "Requirement already satisfied: scikit-learn<0.22,>=0.18 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (0.21.2)\n",
      "Requirement already satisfied: pyarrow<0.15,>=0.14 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (0.14.1)\n",
      "Requirement already satisfied: ipython>=5 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (7.6.1)\n",
      "Requirement already satisfied: protobuf<4,>=3.7 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (3.10.0)\n",
      "Requirement already satisfied: six<2,>=1.12 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (1.13.0)\n",
      "Requirement already satisfied: pandas<1,>=0.24 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (0.24.2)\n",
      "Requirement already satisfied: numpy<2,>=1.16 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (1.17.4)\n",
      "Requirement already satisfied: tensorflow-transform<0.16,>=0.15 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (0.15.0)\n",
      "Requirement already satisfied: absl-py<0.9,>=0.7 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (0.8.1)\n",
      "Requirement already satisfied: tensorflow-metadata<0.16,>=0.15 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (0.15.1)\n",
      "Requirement already satisfied: google-api-python-client>=1.7.8 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from witwidget<2,>=1.4.4->fairness-indicators) (1.7.11)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from witwidget<2,>=1.4.4->fairness-indicators) (7.5.0)\n",
      "Requirement already satisfied: oauth2client>=4.1.3 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from witwidget<2,>=1.4.4->fairness-indicators) (4.1.3)\n",
      "Requirement already satisfied: tensorflow-serving-api>=1.12.0 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from witwidget<2,>=1.4.4->fairness-indicators) (2.0.0)\n",
      "Requirement already satisfied: jupyter<2,>=1.0 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from witwidget<2,>=1.4.4->fairness-indicators) (1.0.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorflow<3,>=1.15->fairness-indicators) (1.25.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorflow<3,>=1.15->fairness-indicators) (0.1.8)\n",
      "Requirement already satisfied: astor>=0.6.0 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorflow<3,>=1.15->fairness-indicators) (0.8.0)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorflow<3,>=1.15->fairness-indicators) (1.15.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorflow<3,>=1.15->fairness-indicators) (1.11.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorflow<3,>=1.15->fairness-indicators) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorflow<3,>=1.15->fairness-indicators) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorflow<3,>=1.15->fairness-indicators) (3.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorflow<3,>=1.15->fairness-indicators) (1.0.8)\n",
      "Requirement already satisfied: gast==0.2.2 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorflow<3,>=1.15->fairness-indicators) (0.2.2)\n",
      "Requirement already satisfied: scipy==1.1.0 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorflow-model-analysis<1,>=0.15.4->fairness-indicators) (1.1.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorboard<2,>=1.14.0->fairness-indicators) (0.15.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorboard<2,>=1.14.0->fairness-indicators) (3.1.1)\n",
      "Requirement already satisfied: mock<3.0.0,>=1.0.1 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (2.0.0)\n",
      "Requirement already satisfied: avro-python3<2.0.0,>=1.8.1; python_version >= \"3.0\" in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (1.9.1)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (1.4.1)\n",
      "Requirement already satisfied: pytz>=2018.3 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (2019.3)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (2.5.8)\n",
      "Requirement already satisfied: future<1.0.0,>=0.16.0 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (0.18.2)\n",
      "Collecting pyyaml<4.0.0,>=3.12 (from apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (3.9.0)\n",
      "Requirement already satisfied: fastavro<0.22,>=0.21.4 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (0.21.24)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (2.8.1)\n",
      "Requirement already satisfied: httplib2<=0.12.0,>=0.8 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (0.12.0)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (1.7)\n",
      "Requirement already satisfied: dill<0.3.1,>=0.3.0 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (0.3.0)\n",
      "Requirement already satisfied: google-cloud-datastore<1.8.0,>=1.7.1; extra == \"gcp\" in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (1.7.4)\n",
      "Requirement already satisfied: google-apitools<0.5.29,>=0.5.28; extra == \"gcp\" in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (0.5.28)\n",
      "Requirement already satisfied: google-cloud-bigtable<1.1.0,>=0.31.1; extra == \"gcp\" in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (1.0.0)\n",
      "Requirement already satisfied: google-cloud-pubsub<1.1.0,>=0.39.0; extra == \"gcp\" in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (1.0.2)\n",
      "Requirement already satisfied: google-cloud-core<2,>=0.28.1; extra == \"gcp\" in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (1.0.3)\n",
      "Requirement already satisfied: cachetools<4,>=3.1.0; extra == \"gcp\" in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (3.1.1)\n",
      "Requirement already satisfied: google-cloud-bigquery<1.18.0,>=1.6.0; extra == \"gcp\" in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (1.17.1)\n",
      "Requirement already satisfied: psutil<6,>=5.6 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tfx-bsl<0.16,>=0.15->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (5.6.3)\n",
      "Requirement already satisfied: backcall in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from ipython>=5->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (0.1.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from ipython>=5->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (4.7.0)\n",
      "Requirement already satisfied: appnope; sys_platform == \"darwin\" in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from ipython>=5->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (0.1.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from ipython>=5->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (0.13.3)\n",
      "Requirement already satisfied: pygments in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from ipython>=5->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (2.4.2)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from ipython>=5->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (2.0.9)\n",
      "Requirement already satisfied: decorator in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from ipython>=5->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (4.4.0)\n",
      "Requirement already satisfied: pickleshare in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from ipython>=5->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from ipython>=5->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (4.3.2)\n",
      "Requirement already satisfied: googleapis-common-protos in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from tensorflow-metadata<0.16,>=0.15->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (1.6.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from google-api-python-client>=1.7.8->witwidget<2,>=1.4.4->fairness-indicators) (0.0.3)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from google-api-python-client>=1.7.8->witwidget<2,>=1.4.4->fairness-indicators) (3.0.0)\n",
      "Requirement already satisfied: google-auth>=1.4.1 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from google-api-python-client>=1.7.8->witwidget<2,>=1.4.4->fairness-indicators) (1.7.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from ipywidgets>=7.0.0->witwidget<2,>=1.4.4->fairness-indicators) (3.5.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from ipywidgets>=7.0.0->witwidget<2,>=1.4.4->fairness-indicators) (4.4.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from ipywidgets>=7.0.0->witwidget<2,>=1.4.4->fairness-indicators) (5.1.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from oauth2client>=4.1.3->witwidget<2,>=1.4.4->fairness-indicators) (0.4.7)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from oauth2client>=4.1.3->witwidget<2,>=1.4.4->fairness-indicators) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from oauth2client>=4.1.3->witwidget<2,>=1.4.4->fairness-indicators) (0.2.7)\n",
      "Requirement already satisfied: notebook in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (6.0.0)\n",
      "Requirement already satisfied: nbconvert in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (5.5.0)\n",
      "Requirement already satisfied: jupyter-console in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (6.0.0)\n",
      "Requirement already satisfied: qtconsole in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (4.5.1)\n",
      "Requirement already satisfied: h5py in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow<3,>=1.15->fairness-indicators) (2.9.0)\n",
      "Requirement already satisfied: pbr>=0.11 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from mock<3.0.0,>=1.0.1->apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (5.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from pydot<2,>=1.2.0->apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (2.4.5)\n",
      "Requirement already satisfied: requests>=2.7.0 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (2.22.0)\n",
      "Requirement already satisfied: docopt in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (0.6.2)\n",
      "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.6.0 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from google-cloud-datastore<1.8.0,>=1.7.1; extra == \"gcp\"->apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (1.14.3)\n",
      "Requirement already satisfied: fasteners>=0.14 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from google-apitools<0.5.29,>=0.5.28; extra == \"gcp\"->apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (0.15)\n",
      "Requirement already satisfied: grpc-google-iam-v1<0.13dev,>=0.12.3 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from google-cloud-bigtable<1.1.0,>=0.31.1; extra == \"gcp\"->apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (0.12.3)\n",
      "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from google-cloud-bigquery<1.18.0,>=1.6.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (0.4.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=5->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (0.6.0)\n",
      "Requirement already satisfied: parso>=0.3.0 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from jedi>=0.10->ipython>=5->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (0.5.0)\n",
      "Requirement already satisfied: wcwidth in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (0.1.7)\n",
      "Requirement already satisfied: ipython-genutils in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from traitlets>=4.2->ipython>=5->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->witwidget<2,>=1.4.4->fairness-indicators) (3.0.1)\n",
      "Requirement already satisfied: jupyter-core in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->witwidget<2,>=1.4.4->fairness-indicators) (4.5.0)\n",
      "Requirement already satisfied: tornado>=4.2 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->witwidget<2,>=1.4.4->fairness-indicators) (6.0.3)\n",
      "Requirement already satisfied: jupyter-client in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->witwidget<2,>=1.4.4->fairness-indicators) (5.3.1)\n",
      "Requirement already satisfied: pyzmq>=17 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from notebook->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (18.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jinja2 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from notebook->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (2.10.1)\n",
      "Requirement already satisfied: Send2Trash in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from notebook->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from notebook->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (0.8.2)\n",
      "Requirement already satisfied: prometheus-client in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from notebook->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (0.7.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (0.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (1.4.2)\n",
      "Requirement already satisfied: bleach in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (3.1.0)\n",
      "Requirement already satisfied: mistune>=0.8.1 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (0.6.0)\n",
      "Requirement already satisfied: testpath in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (0.4.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (1.25.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (3.0.4)\n",
      "Requirement already satisfied: monotonic>=0.1 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from fasteners>=0.14->google-apitools<0.5.29,>=0.5.28; extra == \"gcp\"->apache-beam[gcp]<3,>=2.16->tensorflow-data-validation<1,>=0.15.0->fairness-indicators) (1.5)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->witwidget<2,>=1.4.4->fairness-indicators) (19.1.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->witwidget<2,>=1.4.4->fairness-indicators) (0.14.11)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from jinja2->notebook->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (1.1.1)\n",
      "Requirement already satisfied: webencodings in /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages (from bleach->nbconvert->jupyter<2,>=1.0->witwidget<2,>=1.4.4->fairness-indicators) (0.5.1)\n",
      "\u001b[31mERROR: apache-beam 2.16.0 has requirement oauth2client<4,>=2.0.1, but you'll have oauth2client 4.1.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: pyyaml\n",
      "  Found existing installation: PyYAML 5.1.1\n",
      "\u001b[31mERROR: Cannot uninstall 'PyYAML'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "!pip install fairness-indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B8dlyTyiTe-9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import apache_beam as beam\n",
    "from datetime import datetime\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_analysis as tfma\n",
    "from tensorflow_model_analysis.addons.fairness.view import widget_view\n",
    "from tensorflow_model_analysis.addons.fairness.post_export_metrics import fairness_indicators  # must include to generate the post_export_metrics callback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ekzb7vVnPCc"
   },
   "source": [
    "# Defining Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n4_nXQDykX6W"
   },
   "outputs": [],
   "source": [
    "BASE_DIR = tempfile.gettempdir()\n",
    "\n",
    "# The input and output features of the classifier\n",
    "TEXT_FEATURE = 'comment_text'\n",
    "LABEL = 'toxicity'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TsplOJGqWCf5"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4sZag6SFaMIp"
   },
   "source": [
    "In this exercise, we'll work with the [Civil Comments dataset](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification), approximately 2 million public comments made public by the [Civil Comments platform](https://github.com/reaktivstudios/civil-comments) in 2017 for ongoing research. This effort was sponsored by Jigsaw, who have hosted competitions on Kaggle to help classify toxic comments as well as minimize unintended model bias.\n",
    "\n",
    "Each individual text comment in the dataset has a toxicity label, with the label being 1 if the comment is toxic and 0 if the comment is non-toxic. Within the data, a subset of comments are labeled with a variety of identity attributes, including categories for gender, sexual orientation, religion, and race or ethnicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kBGV8eFZaClA"
   },
   "outputs": [],
   "source": [
    "train_tf_file = tf.keras.utils.get_file('train.tf', 'https://storage.googleapis.com/civil_comments_dataset/train.tfrecord')\n",
    "validate_tf_file = tf.keras.utils.get_file('validate.tf', 'https://storage.googleapis.com/civil_comments_dataset/validate.tfrecord')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NzcVLKPW7sjn"
   },
   "source": [
    "## Identity Terms\n",
    "\n",
    "You can select the subset of identity groups you are interested in by removing the others from the list below. By default, we will look at all identity terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l88BZ7rFKi4-"
   },
   "outputs": [],
   "source": [
    "IDENTITY_TERMS = ['gender', 'sexual_orientation', 'race', 'religion', 'disability']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zz1NLR5Uu3oQ"
   },
   "source": [
    "# Creating a TensorFlow Model Analysis Pipeline\n",
    "\n",
    "The Fairness Indicators library operates on [TensorFlow Model Analysis (TFMA) models](https://www.tensorflow.org/tfx/model_analysis/get_started). TFMA models wrap [TensorFlow models](https://www.tensorflow.org/guide/estimator) with additional functionality to evaluate and visualize their results. The actual evaluation occurs inside of an [Apache Beam pipeline](https://beam.apache.org/documentation/programming-guide/).\n",
    "\n",
    "So we need to...\n",
    "1. Build a TensorFlow model.\n",
    "2. Build a TFMA model on top of the TensorFlow model.\n",
    "3. Run the model analysis in a Beam pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lOUjSzEvxO81"
   },
   "source": [
    "## 1) Build a TensorFlow Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5dIo0yXvQdjo"
   },
   "source": [
    "### Define an Input Function\n",
    "\n",
    "TensorFlow parses features from data using [`FixedLenFeature`](https://www.tensorflow.org/api_docs/python/tf/io/FixedLenFeature) and [`VarLenFeature`](https://www.tensorflow.org/api_docs/python/tf/io/VarLenFeature). So to allow TensorFlow to parse our data, we will need to map out our input feature, output feature, and any slicing features that we will want to analyze via Fairness Indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bFhj0N12SnWv"
   },
   "outputs": [],
   "source": [
    "FEATURE_MAP = {\n",
    "    # input and output features\n",
    "    LABEL: tf.FixedLenFeature([], tf.float32),\n",
    "    TEXT_FEATURE: tf.FixedLenFeature([], tf.string),\n",
    "\n",
    "    # slicing features\n",
    "    'sexual_orientation': tf.VarLenFeature(tf.string),\n",
    "    'gender': tf.VarLenFeature(tf.string),\n",
    "    'religion': tf.VarLenFeature(tf.string),\n",
    "    'race': tf.VarLenFeature(tf.string),\n",
    "    'disability': tf.VarLenFeature(tf.string)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W97S4JhASwe_"
   },
   "source": [
    "Now that we have defined our features and their types, we can create an input function for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3IbTVvhAQgmq"
   },
   "outputs": [],
   "source": [
    "def input_fn(tf_file):\n",
    "  def parse_function(serialized):\n",
    "    parsed_example = tf.io.parse_single_example(\n",
    "        serialized=serialized, features=FEATURE_MAP)\n",
    "    # Adds a weight column to deal with unbalanced classes.\n",
    "    parsed_example['weight'] = tf.add(parsed_example[LABEL], 0.1)\n",
    "    return (parsed_example,\n",
    "            parsed_example[LABEL])\n",
    "  train_dataset = tf.data.TFRecordDataset(\n",
    "      filenames=[tf_file]).map(parse_function).batch(512)\n",
    "  return train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "23i7M_w_bvQu"
   },
   "source": [
    "### Train a Classifier\n",
    "\n",
    "For each text embedding, we will train a **[DNN Classifier](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier)**.\n",
    "\n",
    "**TF Hub** allows us to insert text embeddings as features to our model via **[`text_embedding_column`](https://www.tensorflow.org/hub/api_docs/python/hub/text_embedding_column)**. The function's signature is **`text_embedding_column(key, module_spec)`**, where...\n",
    "\n",
    "* *`key`* is the name of the DataFrame's text feature (ex: `\"comment_text\"`)\n",
    "* *`module_spec`* is a url path to an text embedding module (ex: `\"https://tfhub.dev/google/nnlm-en-dim128/1\"`)\n",
    "\n",
    "Because each text embedding column is memory-intensive, the Colaboratory environment may crash if all embeddings are loaded at once. To avoid this, we encapsulate the embedding columns inside a pipeline and wait to get the pipeline's results before loading the next embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2NJHroV8CrdL"
   },
   "outputs": [],
   "source": [
    "def train_classifier(embedding):\n",
    "  embedded_text_feature_column = hub.text_embedding_column(\n",
    "      key=TEXT_FEATURE, \n",
    "      module_spec=embedding)\n",
    "  model_dir = os.path.join(BASE_DIR, 'train', datetime.now().strftime(\n",
    "    \"%Y%m%d-%H%M%S\"))\n",
    "  classifier = tf.estimator.DNNClassifier(\n",
    "      hidden_units=[500, 100],\n",
    "      weight_column='weight',\n",
    "      feature_columns=[embedded_text_feature_column],\n",
    "      n_classes=2,\n",
    "      optimizer=tf.train.AdagradOptimizer(learning_rate=0.003),\n",
    "      model_dir= model_dir)\n",
    "  classifier.train(input_fn=lambda: input_fn(train_tf_file), steps=1000);\n",
    "  return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nmi2aniNxmfo"
   },
   "source": [
    "## 2) Build a TFMA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hnoxsKIDXAOY"
   },
   "source": [
    "TFMA represents datasets as [`tf.Examples`](https://www.tensorflow.org/tutorials/load_data/tfrecord#tfexample), which it parses with [`EvalInputReceivers`](https://github.com/tensorflow/model-analysis/blob/master/tensorflow_model_analysis/eval_saved_model/export.py#L42). Refer to [Getting Started with TensorFlow Model Analysis](https://www.tensorflow.org/tfx/model_analysis/get_started#modify_an_existing_model) for more info on creating `EvalInputReceivers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DU6BEc41xuHs"
   },
   "outputs": [],
   "source": [
    "def eval_input_receiver_fn():\n",
    "  \"\"\"Create a tfma.export.EvalInputReceiver to parse input features.\"\"\"\n",
    "  serialized_tf_example = tf.compat.v1.placeholder(\n",
    "      dtype=tf.string, shape=[None], name='input_example_placeholder')\n",
    "  receiver_tensors = {'examples': serialized_tf_example}\n",
    "  features = tf.parse_example(serialized_tf_example, FEATURE_MAP)\n",
    "  features['weight'] = tf.ones_like(features[LABEL])\n",
    "  return tfma.export.EvalInputReceiver(\n",
    "    features=features,\n",
    "    receiver_tensors=receiver_tensors,\n",
    "    labels=features[LABEL])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0W5VYoVdW9Tp"
   },
   "source": [
    "TFMA represents models with its **[`EvalSharedModel`](https://github.com/tensorflow/model-analysis/blob/master/tensorflow_model_analysis/types.py#L172)** class, which accepts a list of metrics to evaluate and visualize. TFMA represents metrics as callbacks which are computed after the model is exported - hence, the name **[`post_export_metrics`](https://github.com/tensorflow/model-analysis/blob/master/tensorflow_model_analysis/post_export_metrics/post_export_metrics.py)**. The metric provided by the Fairness Indicators library is **`post_export_metrics.fairness_indicators`**.\n",
    "\n",
    "`EvalSharedModel` is actually a thin wrapper around TFMA's **[`EvalSavedModel`](https://github.com/tensorflow/model-analysis/blob/master/tensorflow_model_analysis/eval_saved_model/load.py#L54)** class. To create an `EvalSavedModel`, we need to pass in a TensorFlow model and an `EvalInputReceiver`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I67Zm4Dc9UE2"
   },
   "outputs": [],
   "source": [
    "def create_tfma_model(classifier, eval_input_receiver_fn, metric_callbacks):\n",
    "\n",
    "  # create EvalSavedModel\n",
    "  eval_saved_model_path = tfma.export.export_eval_savedmodel(\n",
    "      estimator=classifier,\n",
    "      export_dir_base=os.path.join(BASE_DIR, 'tfma_eval_model'),\n",
    "      eval_input_receiver_fn=eval_input_receiver_fn)\n",
    "\n",
    "  # create EvalSharedModel\n",
    "  return tfma.default_eval_shared_model(\n",
    "        eval_saved_model_path=eval_saved_model_path,\n",
    "        add_metrics_callbacks=metric_callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HbCbLLbWZLT"
   },
   "source": [
    "## 3) Get Evaluation Results in Apache Beam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "geCqkTyMW5Nr"
   },
   "source": [
    "Our [Model Evaluation pipeline](https://www.tensorflow.org/tfx/model_analysis/get_started) will have two steps. The first step is to read in the data in a TF-compatible format - we can use [`beam.io.ReadFromTFRecord`](https://beam.apache.org/releases/pydoc/2.15.0/apache_beam.io.tfrecordio.html#apache_beam.io.tfrecordio.ReadFromTFRecord) for that.\n",
    "\n",
    "The second step is to evaluate the TFMA results. We use TFMA's [`ExtractEvaluateAndWriteResults`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/ExtractEvaluateAndWriteResults) API, a [`PTransform`](https://beam.apache.org/documentation/programming-guide/#transforms) that takes in an `EvalSharedModel`, computes metrics for the slices specified in `slice_spec`, and writes them to an `output_path`.\n",
    "\n",
    "[`slice_spec`](https://www.tensorflow.org/tfx/tutorials/model_analysis/tfma_basic#slicing_and_dicing) is how TFMA decides how to group the data. In this case study, the slices refer to different identity groups. We'll show you how to create a `slice_spec` in the next section.\n",
    "\n",
    "Check the [Get Started with TensorFlow Model Analysis](https://www.tensorflow.org/tfx/model_analysis/get_started) tutorial for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKh1Ale0KynF"
   },
   "outputs": [],
   "source": [
    "def get_eval_result(input_file, eval_shared_model,\n",
    "                    slice_spec, eval_result_path):\n",
    "  with beam.Pipeline() as pipeline:\n",
    "    _ = (\n",
    "        pipeline\n",
    "        | 'ReadFromTFRecord' >> beam.io.ReadFromTFRecord(\n",
    "            file_pattern=input_file)\n",
    "        | 'ExtractEvaluateAndWriteResults' >>\n",
    "        tfma.ExtractEvaluateAndWriteResults(\n",
    "                  eval_shared_model=eval_shared_model,\n",
    "                  slice_spec=slice_spec,\n",
    "                  compute_confidence_intervals=False,\n",
    "                  output_path=eval_result_path)\n",
    "    )\n",
    "  return tfma.load_eval_result(output_path=eval_result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wM-faceoCPqg"
   },
   "source": [
    "# Putting it all Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7nSvu4IUCigW"
   },
   "outputs": [],
   "source": [
    "def embedding_fairness_result(embedding):\n",
    "\n",
    "  # First, we use our train_classifier() function to train a basic classifier\n",
    "  # with our chosen embedding.\n",
    "  print(\"Training classifier for \" + embedding)\n",
    "  classifier = train_classifier(embedding)\n",
    "\n",
    "  # Next, we measure the accuracy of our classifier on our validation set.\n",
    "  train_eval_result = classifier.evaluate(input_fn=lambda: input_fn(validate_tf_file))\n",
    "  print('Validation set accuracy for {}: {accuracy}'.format(embedding, **train_eval_result))\n",
    "\n",
    "  # We then create a fairness_indicators callback to use in our TFMA model.\n",
    "  # `labels_key` is the target feature (\"toxicity\" in our case).\n",
    "  # `thresholds` are the values of the target feature at which to measure fairness metrics.\n",
    "  fairness_indicator_callback = tfma.post_export_metrics.fairness_indicators(\n",
    "                                    thresholds=[0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "                                    labels_key=LABEL)\n",
    "\n",
    "  # We then use our create_tfma_model() function, which converts our classifier\n",
    "  # to a TFMA EvalSharedModel that outputs Fairness Indicators.\n",
    "  eval_shared_model = create_tfma_model(classifier, eval_input_receiver_fn,\n",
    "                                        [fairness_indicator_callback])\n",
    "\n",
    "  # We select the slices we want to compute Fairness results for.\n",
    "  # In this case, we use the same identity terms that you selected at the\n",
    "  # beginning of the colab.\n",
    "  slice_spec = [tfma.slicer.SingleSliceSpec()]\n",
    "  for identity in IDENTITY_TERMS:\n",
    "    slice_spec.append(tfma.slicer.SingleSliceSpec(columns=[identity]))\n",
    "\n",
    "  # We also need to create a unique path to store our results for this embedding.\n",
    "  embedding_name = embedding.split('/')[-2]\n",
    "  eval_result_path = os.path.join(BASE_DIR, 'eval_result', embedding_name)\n",
    "\n",
    "  # Finally, we use our get_eval_result() function to compute and return the\n",
    "  # Fairness Indicators results!\n",
    "  eval_result = get_eval_result(validate_tf_file, eval_shared_model, slice_spec, eval_result_path)\n",
    "  return eval_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jTPqije9Eg5b"
   },
   "source": [
    "# Run TFMA & Fairness Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8AvInTNt8Gyn"
   },
   "source": [
    "## Fairness Indicators Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jiLg5ikCzFR-"
   },
   "source": [
    "Refer [here](https://github.com/tensorflow/fairness-indicators) for more information on Fairness Indicators. Below are some of the available metrics.\n",
    "\n",
    "* [Negative Rate, False Negative Rate (FNR), and True Negative Rate (TNR)](https://en.wikipedia.org/wiki/False_positives_and_false_negatives#False_positive_and_false_negative_rates)\n",
    "* [Positive Rate, False Positive Rate (FPR), and True Positive Rate (TPR)](https://en.wikipedia.org/wiki/False_positives_and_false_negatives#False_positive_and_false_negative_rates)\n",
    "* [Accuracy](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Accuracy)\n",
    "* [Precision and Recall](https://en.wikipedia.org/wiki/Precision_and_recall)\n",
    "* [Precision-Recall AUC](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/AUC)\n",
    "* [ROC AUC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LGXCFtScblYt"
   },
   "source": [
    "## Text Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1CI-1M5qXGjG"
   },
   "source": [
    "**[TF-Hub](https://www.tensorflow.org/hub)** provides several **text embeddings**. These embeddings will serve as the feature column for our different models. For this Colab, we use the following embeddings:\n",
    "\n",
    "* [**random-nnlm-en-dim128**](https://tfhub.dev/google/random-nnlm-en-dim128/1): random text embeddings, this serves as a convenient baseline.\n",
    "* [**nnlm-en-dim128**](https://tfhub.dev/google/nnlm-en-dim128/1): a text embedding based on [A Neural Probabilistic Language Model](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf). \n",
    "* [**universal-sentence-encoder**](https://tfhub.dev/google/universal-sentence-encoder/2): a text embedding based on [Universal Sentence Encoder](https://arxiv.org/pdf/1803.11175.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xxq97Qt7itVL"
   },
   "source": [
    "## Fairness Indicator Resutls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "27FX15awixuK"
   },
   "source": [
    "For each of the above embeddings, we will compute fairness indicators with our `embedding_fairness_result` pipeline, and then render the results in the Fairness Indicator UI widget with `widget_view.render_fairness_indicator`.\n",
    "\n",
    "Note that the `widget_view.render_fairness_indicator` cells may need to be run twice for the visualization to be displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yEUbZ93y8NCW"
   },
   "source": [
    "#### Random NNLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DkSuox-Pb6Pz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier for https://tfhub.dev/google/random-nnlm-en-dim128/1\n",
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hx/wn5qgb193wx3hbk4m0zfk6nw0000gp/T/train/20191115-095812', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1332e2d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hx/wn5qgb193wx3hbk4m0zfk6nw0000gp/T/train/20191115-095812', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1332e2d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/nazneen.rajani/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    }
   ],
   "source": [
    "eval_result_random_nnlm = embedding_fairness_result('https://tfhub.dev/google/random-nnlm-en-dim128/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05xUesz6VpAe"
   },
   "outputs": [],
   "source": [
    "widget_view.render_fairness_indicator(eval_result_random_nnlm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jmKe8Z1b8SBy"
   },
   "source": [
    "##### NNLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5b8HcTUBckj1"
   },
   "outputs": [],
   "source": [
    "eval_result_nnlm = embedding_fairness_result('https://tfhub.dev/google/nnlm-en-dim128/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n6hasLzFVrDN"
   },
   "outputs": [],
   "source": [
    "widget_view.render_fairness_indicator(eval_result_nnlm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1I4xEDNq8T0X"
   },
   "source": [
    "##### Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GrdweWRkck8A"
   },
   "outputs": [],
   "source": [
    "eval_result_use = embedding_fairness_result('https://tfhub.dev/google/universal-sentence-encoder/2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JBABAkZMVtTK"
   },
   "outputs": [],
   "source": [
    "widget_view.render_fairness_indicator(eval_result_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O2AnFO6Hcofi"
   },
   "source": [
    "## Exercises\n",
    "1. Pick an identity category, such as religion or sexual orientation, and look at False Positive Rate for the Universal Sentence Encoder. How do different slices compare to each other? How do they compare to the Overall baseline?\n",
    "2. Now pick a different identity category. Compare the results of this category with the previous one. Does the model weigh one category as more \"toxic\" than the other? Does this change with the embedding used?\n",
    "3. Does the model generally tend to overestimate or underestimate the number of toxic comments?\n",
    "4. Look at the graphs for different fairness metrics. Which metrics seem most informative? Which embeddings perform best and worst for that metric?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Fairness Indicators on TF-Hub Text Embeddings",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
